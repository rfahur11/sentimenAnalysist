{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi Sentimen: positif\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# 1. Definisikan arsitektur model persis sama dengan saat training.\n",
    "class IndoBERT_BiLSTM(nn.Module):\n",
    "    def __init__(self, bert_model=\"indobenchmark/indobert-base-p1\", lstm_hidden=128, num_classes=3):\n",
    "        super(IndoBERT_BiLSTM, self).__init__()\n",
    "        \n",
    "        # Load IndoBERT sebagai feature extractor.\n",
    "        self.bert = AutoModel.from_pretrained(bert_model)\n",
    "        self.bert.requires_grad_(False)  # Freeze bobot IndoBERT agar tidak berubah saat inferensi.\n",
    "        \n",
    "        # BiLSTM untuk memproses representasi vektor dari IndoBERT.\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=768, \n",
    "            hidden_size=lstm_hidden, \n",
    "            num_layers=2,\n",
    "            batch_first=True, \n",
    "            bidirectional=True, \n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        # Batch Normalization dan Dropout untuk membantu stabilitas.\n",
    "        self.batch_norm = nn.BatchNorm1d(lstm_hidden * 2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Fully Connected layer untuk menghasilkan prediksi kelas.\n",
    "        self.fc = nn.Linear(lstm_hidden * 2, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Ekstraksi fitur dengan IndoBERT.\n",
    "        with torch.no_grad():\n",
    "            bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Mengambil representasi token [CLS] (index 0) sebagai representasi kalimat.\n",
    "        bert_embedding = bert_output.last_hidden_state[:, 0, :]  # Bentuk: [batch_size, 768]\n",
    "        \n",
    "        # Proses dengan BiLSTM. Karena LSTM mengharapkan input 3 dimensi, kita tambahkan dimensi sekuens.\n",
    "        lstm_out, _ = self.lstm(bert_embedding.unsqueeze(1))  # Bentuk: [batch_size, seq_len=1, hidden_size*2]\n",
    "        lstm_out = lstm_out[:, -1, :]  # Ambil output terakhir dari LSTM.\n",
    "        \n",
    "        # Normalisasi dan dropout.\n",
    "        lstm_out = self.batch_norm(lstm_out)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        # Prediksi akhir.\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\n",
    "# 2. Inisialisasi model dan device.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = IndoBERT_BiLSTM().to(device)\n",
    "\n",
    "# 3. Load bobot model yang telah disimpan.\n",
    "# Pastikan file \"best_model.pth\" berada di direktori kerja Anda.\n",
    "model.load_state_dict(torch.load(\"./model/best_model.pth\", map_location=device))\n",
    "model.eval()  # Set model ke mode evaluasi.\n",
    "\n",
    "# 4. Load tokenizer yang sama dengan saat training.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "\n",
    "# 5. Buat mapping label.\n",
    "# Misalnya: {0: \"negatif\", 1: \"netral\", 2: \"positif\"}\n",
    "label_mapping = {0: \"negatif\", 1: \"netral\", 2: \"positif\"}\n",
    "\n",
    "# 6. Fungsi prediksi.\n",
    "def predict(text, model, tokenizer, device, label_mapping):\n",
    "    \"\"\"\n",
    "    Fungsi untuk melakukan prediksi sentimen pada input teks.\n",
    "    Args:\n",
    "        text (str): Komentar atau kalimat input.\n",
    "        model: Model yang telah diload.\n",
    "        tokenizer: Tokenizer IndoBERT.\n",
    "        device: Device yang digunakan (CPU atau GPU).\n",
    "        label_mapping (dict): Mapping indeks ke label (misal: 0->\"negatif\").\n",
    "    Returns:\n",
    "        str: Label sentimen prediksi.\n",
    "    \"\"\"\n",
    "    model.eval()  # Pastikan model dalam mode evaluasi.\n",
    "    \n",
    "    # Tokenisasi teks input.\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Lakukan inferensi tanpa gradien.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "    \n",
    "    # Ambil indeks prediksi dengan nilai tertinggi.\n",
    "    pred_idx = torch.argmax(outputs, dim=1).item()\n",
    "    return label_mapping[pred_idx]\n",
    "\n",
    "# 7. Contoh penggunaan prediksi.\n",
    "example_text = \"Produk ini sangat bagus dan berkualitas!\"\n",
    "prediction = predict(example_text, model, tokenizer, device, label_mapping)\n",
    "print(f\"Prediksi Sentimen: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi Sentimen: negatif\n"
     ]
    }
   ],
   "source": [
    "example_text = \"Produk ini sangat jelek\"\n",
    "prediction = predict(example_text, model, tokenizer, device, label_mapping)\n",
    "print(f\"Prediksi Sentimen: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi Sentimen: negatif\n"
     ]
    }
   ],
   "source": [
    "example_text = \"aku udahh Beli nantii aku Komen lagi Kalo ada perubahan\"\n",
    "prediction = predict(example_text, model, tokenizer, device, label_mapping)\n",
    "print(f\"Prediksi Sentimen: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"./test_comments_with_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m---> 43\u001b[0m     pred_label \u001b[38;5;241m=\u001b[39m predict(comment, \u001b[43mmodel\u001b[49m, tokenizer)\n\u001b[0;32m     44\u001b[0m     predicted_labels\u001b[38;5;241m.\u001b[39mappend(pred_label)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# 5. Tambahkan hasil prediksi ke dataset\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1. Load dataset CSV yang berisi komentar\n",
    "test_df = pd.read_csv(\"./dataset/comments.csv\")  # Ganti dengan path file Anda\n",
    "\n",
    "# Pastikan kolom \"comment\" ada di dataset\n",
    "if \"comment\" not in test_df.columns:\n",
    "    raise ValueError(\"Kolom 'comment' tidak ditemukan dalam dataset!\")\n",
    "\n",
    "# 2. Bersihkan dataset (pastikan semua komentar bertipe string)\n",
    "test_df[\"comment\"] = test_df[\"comment\"].astype(str)  # Konversi semua ke string\n",
    "test_df[\"comment\"] = test_df[\"comment\"].fillna(\"\")   # Jika ada NaN, ganti dengan string kosong\n",
    "\n",
    "# 3. Definisikan ulang fungsi prediksi dengan validasi input\n",
    "def predict(text, model, tokenizer):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return \"netral\"  # Label default jika komentar kosong atau tidak valid\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask)\n",
    "    \n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "    \n",
    "    mapping = {0: \"negatif\", 1: \"netral\", 2: \"positif\"}\n",
    "    return mapping[pred_class]\n",
    "\n",
    "# 4. Lakukan prediksi untuk setiap komentar di dataset\n",
    "predicted_labels = []\n",
    "for comment in test_df[\"comment\"]:\n",
    "    pred_label = predict(comment, model, tokenizer)\n",
    "    predicted_labels.append(pred_label)\n",
    "\n",
    "# 5. Tambahkan hasil prediksi ke dataset\n",
    "test_df[\"predicted_label\"] = predicted_labels\n",
    "\n",
    "# 6. Simpan hasil prediksi ke file CSV baru\n",
    "output_path = \"test_comments_with_predictions.csv\"\n",
    "test_df.to_csv(output_path, index=False)\n",
    "print(f\"Hasil prediksi telah disimpan ke {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>comment</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Aku cuma pake sunscreen dan krim ini doang, al...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Simpen dulu di keranjang kuning, nanti check out.</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Muka kusamku jadi segeran setelah rutin pake k...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Aku cuma pake sunscreen dan krim ini doang, al...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Masih menjadi misteri kenapa Dr. Fay bisa seba...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                            comment predicted_label\n",
       "0   1  Aku cuma pake sunscreen dan krim ini doang, al...         positif\n",
       "1   2  Simpen dulu di keranjang kuning, nanti check out.         negatif\n",
       "2   3  Muka kusamku jadi segeran setelah rutin pake k...         positif\n",
       "3   4  Aku cuma pake sunscreen dan krim ini doang, al...         positif\n",
       "4   5  Masih menjadi misteri kenapa Dr. Fay bisa seba...         negatif"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagus sekali, saya suka! -> positif\n",
      "Tidak bagus sama sekali -> negatif\n",
      "Biasa saja tidak terlalu buruk atau bagus -> netral\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 1. Siapkan kamus kata sentimen\n",
    "positive_words = {\"bagus\", \"baik\", \"indah\", \"cerah\", \"puas\", \"suka\", \"alhamdulillah\"}\n",
    "negative_words = {\"buruk\", \"jelek\", \"kecewa\", \"mengecewakan\"}\n",
    "negation_words = {\"tidak\", \"bukan\", \"kurang\", \"belum\"}\n",
    "\n",
    "def preprocess_negation(text):\n",
    "    \"\"\"\n",
    "    - Ubah ke huruf kecil dan ekstrak hanya kata (tanpa tanda baca)\n",
    "    - Jika menemukan kata negasi dan kata berikutnya ada dalam positive atau negative words,\n",
    "      maka tandai kata berikutnya dengan prefix \"NEG_\" (untuk positive) atau \"POS_\" (untuk negative)\n",
    "    - Jika tidak, proses kata seperti biasa\n",
    "    \"\"\"\n",
    "    # Ekstrak kata dengan regex agar tanda baca tidak ikut\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    new_words = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        word = words[i]\n",
    "        # Jika kata merupakan negasi dan ada kata setelahnya\n",
    "        if word in negation_words and i + 1 < len(words):\n",
    "            next_word = words[i+1]\n",
    "            # Jika kata berikutnya termasuk kata positif, tandai dengan \"NEG_\"\n",
    "            if next_word in positive_words:\n",
    "                new_words.append(\"NEG_\" + next_word)\n",
    "                i += 2  # Lewati kata negasi dan kata yang ditandai\n",
    "                continue\n",
    "            # Jika kata berikutnya termasuk kata negatif, tandai dengan \"POS_\"\n",
    "            elif next_word in negative_words:\n",
    "                new_words.append(\"POS_\" + next_word)\n",
    "                i += 2\n",
    "                continue\n",
    "            else:\n",
    "                # Jika kata berikutnya bukan kata sentimen, simpan kata negasi dan lanjutkan\n",
    "                new_words.append(word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "        i += 1\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "def sentiment_score(text):\n",
    "    \"\"\"\n",
    "    Fungsi ini menghitung skor sentimen berdasarkan:\n",
    "      - Menambahkan +1 untuk setiap kata positif\n",
    "      - Mengurangi -1 untuk setiap kata negatif\n",
    "      - Untuk kata yang diberi prefix \"NEG_\", mengurangi -1 (karena kata positif yang dinetralkan)\n",
    "      - Untuk kata dengan prefix \"POS_\", menambahkan +1 (karena kata negatif yang dibalik artinya)\n",
    "    \"\"\"\n",
    "    processed_text = preprocess_negation(text)\n",
    "    score = 0\n",
    "    words = processed_text.split()\n",
    "    for word in words:\n",
    "        if word in positive_words:\n",
    "            score += 1\n",
    "        elif word in negative_words:\n",
    "            score -= 1\n",
    "        elif word.startswith(\"NEG_\"):\n",
    "            # Kata positif yang di-negate dihitung sebagai negatif\n",
    "            if word[4:] in positive_words:\n",
    "                score -= 1\n",
    "        elif word.startswith(\"POS_\"):\n",
    "            # Kata negatif yang di-negate dihitung sebagai positif\n",
    "            if word[4:] in negative_words:\n",
    "                score += 1\n",
    "    if score > 0:\n",
    "        return \"positif\"\n",
    "    elif score < 0:\n",
    "        return \"negatif\"\n",
    "    else:\n",
    "        return \"netral\"\n",
    "\n",
    "# Contoh pengujian:\n",
    "texts = [\n",
    "    \"Bagus sekali, saya suka!\",         # Seharusnya: positif\n",
    "    \"Tidak bagus sama sekali\",            # Seharusnya: negatif\n",
    "    \"Biasa saja tidak terlalu buruk atau bagus\"  # Seharusnya: netral\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    print(f\"{text} -> {sentiment_score(text)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
