{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3766 entries, 0 to 3765\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   No.      3766 non-null   int64 \n",
      " 1   comment  3766 non-null   object\n",
      " 2   label    3766 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 88.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   No.                                            comment    label\n",
       " 0    1  Produk ini sangat bagus! Kulitku jadi lebih ha...  Positif\n",
       " 1    2  Aku kecewa, tidak ada perubahan setelah pemaka...  Negatif\n",
       " 2    3  Biasa saja, tidak terlalu buruk tapi juga tida...   Netral\n",
       " 3    4  Wanginya enak dan cepat meresap ke kulit, suka...  Positif\n",
       " 4    5  Teksturnya terlalu lengket dan bikin wajahku b...  Negatif,\n",
       " None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"../dataset/fileconverts (2).csv\"\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "dataset.head(), dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.        0\n",
      "comment    0\n",
      "label      0\n",
      "dtype: int64\n",
      "\n",
      "‚ùì Jumlah Missing Values:\n",
      "No.        0\n",
      "comment    0\n",
      "label      0\n",
      "dtype: int64\n",
      "\n",
      "‚ôªÔ∏è Jumlah Duplikat: 1399\n"
     ]
    }
   ],
   "source": [
    "# Cek jumlah nilai yang hilang\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "print(\"\\n‚ùì Jumlah Missing Values:\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "print(\"\\n‚ôªÔ∏è Jumlah Duplikat:\", dataset.duplicated(subset=['comment']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3766 entries, 0 to 3765\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   No.      3766 non-null   int64 \n",
      " 1   comment  3766 non-null   object\n",
      " 2   label    3766 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 88.4+ KB\n",
      "No.        0\n",
      "comment    0\n",
      "label      0\n",
      "dtype: int64\n",
      "\n",
      "‚ùì Jumlah Missing Values:\n",
      "No.        0\n",
      "comment    0\n",
      "label      0\n",
      "dtype: int64\n",
      "\n",
      "‚ôªÔ∏è Jumlah Duplikat: 1399\n",
      "No.        0\n",
      "comment    0\n",
      "label      0\n",
      "dtype: int64\n",
      "\n",
      "‚ùì Jumlah Missing Values:\n",
      "No.        0\n",
      "comment    0\n",
      "label      0\n",
      "dtype: int64\n",
      "\n",
      "‚ôªÔ∏è Jumlah Duplikat: 1399\n",
      "‚úÖ Shape setelah cleaning: (2367, 3)\n",
      "‚úÖ Jumlah Missing Values baru: No.        0\n",
      "comment    0\n",
      "label      0\n",
      "dtype: int64\n",
      "\n",
      "üìù Contoh Data Bersih:\n",
      "                                             comment\n",
      "0  Produk ini sangat bagus! Kulitku jadi lebih ha...\n",
      "1  Aku kecewa, tidak ada perubahan setelah pemaka...\n",
      "2  Biasa saja, tidak terlalu buruk tapi juga tida...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rfahr\\AppData\\Local\\Temp\\ipykernel_9064\\4160418096.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleanedDatasetTest['comment'] = DatasetTest['comment'].str.lower()\n",
      "C:\\Users\\rfahr\\AppData\\Local\\Temp\\ipykernel_9064\\4160418096.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleanedDatasetTest['label'] = DatasetTest['label'].str.lower()\n",
      "C:\\Users\\rfahr\\AppData\\Local\\Temp\\ipykernel_9064\\4160418096.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleanedDatasetTest['comment'] = DatasetTest['comment'].str.replace(\n",
      "C:\\Users\\rfahr\\AppData\\Local\\Temp\\ipykernel_9064\\4160418096.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleanedDatasetTest['comment'] = DatasetTest['comment'].str.strip()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"../dataset/fileconverts (2).csv\"\n",
    "DatasetTest = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DatasetTest to understand its structure\n",
    "DatasetTest.head(), DatasetTest.info()\n",
    "\n",
    "##### Cek Kondisi Dataset #####\n",
    "# Cek jumlah nilai yang hilang\n",
    "print(DatasetTest.isnull().sum())\n",
    "\n",
    "print(\"\\n‚ùì Jumlah Missing Values:\")\n",
    "print(DatasetTest.isnull().sum())\n",
    "\n",
    "print(\"\\n‚ôªÔ∏è Jumlah Duplikat:\", DatasetTest.duplicated(subset=['comment']).sum())\n",
    "\n",
    "# Cek jumlah nilai yang hilang\n",
    "print(DatasetTest.isnull().sum())\n",
    "\n",
    "print(\"\\n‚ùì Jumlah Missing Values:\")\n",
    "print(DatasetTest.isnull().sum())\n",
    "\n",
    "print(\"\\n‚ôªÔ∏è Jumlah Duplikat:\", DatasetTest.duplicated(subset=['comment']).sum())\n",
    "\n",
    "\n",
    "##### Pembersihan Dataset #####\n",
    "\n",
    "# Ganti sinonim\n",
    "synonym_dict = {\n",
    "    **{word: \"tidak\" for word in {\"gk\", \"gak\", \"tdk\", \"ga\", \"nggak\"}},\n",
    "    **{word: \"cerah\" for word in {\"berkilau\", \"glowing\"}},\n",
    "    **{word: \"dari\" for word in {\"dr\"}}\n",
    "}\n",
    "\n",
    "\n",
    "def replace_synonyms(text):\n",
    "    words = text.split()\n",
    "    words = [synonym_dict.get(word, word) for word in words]  # Ganti kata jika ada di dictionary\n",
    "    return \" \".join(words)\n",
    "\n",
    "cleaneddataset['comment'] = cleaneddataset['comment'].apply(replace_synonyms)\n",
    "\n",
    "# ganti emoji ke teks\n",
    "import emoji\n",
    "\n",
    "def replace_emojis(text):\n",
    "    return emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "\n",
    "# Hapus baris dengan komentar null (10 data)\n",
    "cleanedDatasetTest = DatasetTest.dropna(subset=['comment'])\n",
    "\n",
    "# Hapus baris dengan komentar duplikat\n",
    "cleanedDatasetTest = DatasetTest.drop_duplicates(subset=['comment'], keep='first')\n",
    "\n",
    "# Case folding\n",
    "cleanedDatasetTest['comment'] = DatasetTest['comment'].str.lower()\n",
    "cleanedDatasetTest['label'] = DatasetTest['label'].str.lower()\n",
    "\n",
    "# Remove special characters (sesuaikan dengan kebutuhan)\n",
    "cleanedDatasetTest['comment'] = DatasetTest['comment'].str.replace(\n",
    "    r'[^\\w\\s]', '', regex=True\n",
    ")\n",
    "\n",
    "# Remove extra whitespace\n",
    "cleanedDatasetTest['comment'] = DatasetTest['comment'].str.strip()\n",
    "\n",
    "print(\"‚úÖ Shape setelah cleaning:\", cleanedDatasetTest.shape)\n",
    "print(\"‚úÖ Jumlah Missing Values baru:\", cleanedDatasetTest.isnull().sum())\n",
    "print(\"\\nüìù Contoh Data Bersih:\")\n",
    "print(cleanedDatasetTest[['comment']].head(3))\n",
    "\n",
    "cleanedDatasetTest.to_csv(\"../dataset/cleaned-valDataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shape setelah cleaning: (2367, 3)\n",
      "‚úÖ Jumlah Missing Values baru: No.        0\n",
      "comment    0\n",
      "label      0\n",
      "dtype: int64\n",
      "\n",
      "üìù Contoh Data Bersih:\n",
      "                                             comment\n",
      "0  Produk ini sangat bagus! Kulitku jadi lebih ha...\n",
      "1  Aku kecewa, tidak ada perubahan setelah pemaka...\n",
      "2  Biasa saja, tidak terlalu buruk tapi juga tida...\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Shape setelah cleaning:\", cleanedDatasetTest.shape)\n",
    "print(\"‚úÖ Jumlah Missing Values baru:\", cleanedDatasetTest.isnull().sum())\n",
    "print(\"\\nüìù Contoh Data Bersih:\")\n",
    "print(cleanedDatasetTest[['comment']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rfahr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   no                                            comment predicted_label\n",
      "0   1  Aku cuma pake sunscreen dan krim ini doang, al...         positif\n",
      "1   2  Simpen dulu di keranjang kuning, nanti check out.         negatif\n",
      "2   3  Muka kusamku jadi segeran setelah rutin pake k...         positif\n",
      "3   4  Aku cuma pake sunscreen dan krim ini doang, al...         positif\n",
      "4   5  Masih menjadi misteri kenapa Dr. Fay bisa seba...         negatif\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   no               1000 non-null   int64 \n",
      " 1   comment          990 non-null    object\n",
      " 2   predicted_label  1000 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 23.6+ KB\n",
      "\n",
      "‚ùì Jumlah Missing Values:\n",
      "no                  0\n",
      "comment            10\n",
      "predicted_label     0\n",
      "dtype: int64\n",
      "\n",
      "‚ôªÔ∏è Jumlah Duplikat: 946\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "# Pastikan library Sastrawi sudah terinstall: pip install Sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords Bahasa Indonesia (hanya diperlukan jika belum pernah diunduh)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Inisialisasi stopwords dan stemmer\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def remove_stopwords_and_stem(text):\n",
    "    \"\"\"\n",
    "    Fungsi untuk menghapus stopwords dan melakukan stemming pada teks.\n",
    "    \"\"\"\n",
    "    # Tokenisasi (pisahkan berdasarkan spasi)\n",
    "    tokens = text.split()\n",
    "    # Hapus stopwords\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lakukan stemming pada setiap token\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "# --- Load Dataset ---\n",
    "file_path = \"../dataset/recommendation/test_comments_with_predictions.csv\"\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Tampilkan beberapa baris awal dan informasi dataset\n",
    "print(dataset.head())\n",
    "dataset.info()\n",
    "\n",
    "# --- Cek Kondisi Dataset ---\n",
    "print(\"\\n‚ùì Jumlah Missing Values:\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "print(\"\\n‚ôªÔ∏è Jumlah Duplikat:\", dataset.duplicated(subset=['comment']).sum())\n",
    "\n",
    "# --- Pembersihan Dataset ---\n",
    "\n",
    "# Synonim case\n",
    "synonym_dict = {\n",
    "    **{word: \"tidak\" for word in {\"gk\", \"gak\", \"tdk\", \"ga\", \"nggak\"}},\n",
    "    **{word: \"cerah\" for word in {\"berkilau\", \"glowing\"}},\n",
    "}\n",
    "\n",
    "def replace_synonyms(text):\n",
    "    words = text.split()\n",
    "    words = [synonym_dict.get(word, word) for word in words]  # Ganti kata jika ada di dictionary\n",
    "    return \" \".join(words)\n",
    "\n",
    "cleaneddataset['comment'] = cleaneddataset['comment'].apply(replace_synonyms)\n",
    "\n",
    "# # Ganti emoji ke teks\n",
    "# import emoji\n",
    "\n",
    "# def replace_emojis(text):\n",
    "#     return emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "\n",
    "# cleaneddataset['comment'] = cleaneddataset['comment'].apply(replace_emojis)\n",
    "\n",
    "# Hapus baris dengan komentar null\n",
    "cleaneddataset = dataset.dropna(subset=['comment'])\n",
    "\n",
    "# Hapus baris dengan komentar duplikat\n",
    "cleaneddataset = cleaneddataset.drop_duplicates(subset=['comment'], keep='first')\n",
    "\n",
    "# Case folding: ubah semua teks ke huruf kecil\n",
    "cleaneddataset['comment'] = cleaneddataset['comment'].str.lower()\n",
    "cleaneddataset['predicted_label'] = cleaneddataset['predicted_label'].str.lower()\n",
    "\n",
    "# Remove special characters (sesuaikan dengan kebutuhan)\n",
    "cleaneddataset['comment'] = cleaneddataset['comment'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# Remove extra whitespace\n",
    "cleaneddataset['comment'] = cleaneddataset['comment'].str.strip()\n",
    "\n",
    "# --- Tambahan: Stopwords Removal & Stemming ---\n",
    "cleaneddataset['comment'] = cleaneddataset['comment'].apply(remove_stopwords_and_stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shape setelah cleaning: (53, 3)\n",
      "‚úÖ Jumlah Missing Values baru: no                 0\n",
      "comment            0\n",
      "predicted_label    0\n",
      "dtype: int64\n",
      "‚úÖ Jumlah data duplicated: 0\n",
      "\n",
      "üìù Contoh Data Bersih:\n",
      "                                             comment\n",
      "0  pake sunscreen krim doang alhamdulillah tahun ...\n",
      "1                  simpen keranjang kuning check out\n",
      "2                 muka kusam segeran rutin pake krim\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tampilkan hasil cleaning\n",
    "print(\"‚úÖ Shape setelah cleaning:\", cleaneddataset.shape)\n",
    "print(\"‚úÖ Jumlah Missing Values baru:\", cleaneddataset.isnull().sum())\n",
    "print(\"‚úÖ Jumlah Comments duplicated:\", cleaneddataset.duplicated(subset=['comment']).sum())\n",
    "print(\"\\nüìù Contoh Data Bersih:\")\n",
    "print(cleaneddataset[['comment']].head(3))\n",
    "\n",
    "# Simpan data hasil cleaning (opsional)\n",
    "# cleaneddataset.to_csv(\"./dataset/cleaned_test_comments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synonim case\n",
    "synonym_dict = {\n",
    "    **{word: \"tidak\" for word in {\"gk\", \"gak\", \"tdk\", \"ga\", \"nggak\"}},\n",
    "    **{word: \"cerah\" for word in {\"berkilau\", \"glowing\"}},\n",
    "}\n",
    "\n",
    "def replace_synonyms(text):\n",
    "    words = text.split()\n",
    "    words = [synonym_dict.get(word, word) for word in words]  # Ganti kata jika ada di dictionary\n",
    "    return \" \".join(words)\n",
    "\n",
    "cleaneddataset['comment'] = cleaneddataset['comment'].apply(replace_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>comment</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pake sunscreen krim doang alhamdulillah tahun ...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>simpen keranjang kuning check out</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>muka kusam segeran rutin pake krim</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>misteri dr fay bagus</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>banyakin produk kayak gin anak kuliah minim bu...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>udah check out kak kemarin udah abis cocok banget</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>orang tidak percaya kalo beli online kali beli...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>pake alhamdulillah hasil udah liat</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>hasil nyata bagus banget</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>cocok banget makasih</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>kak udah abis 3 pot nih udah langgan bonusin</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>krim ringan tidak lengket bikin kulit halus</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>caricari ketemu</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>langgan mah ngerasain banget insecurenya</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>dibeliin istri pake emang sabar</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>suka banget produk</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>tementemenku nanyain pake skincare muka ku cerah</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>bau enak tidak nyengat</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>2 bulan udah pudar pudar total udah bantu itun...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>pakenya gampang cepet resap</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>hasil maksimal pake rutin tidur hasil bagus kayak</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>saranin kalo hasil bagus pake facial wash pake...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>tidak rasa bulan pake udah hasil aja</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>tekstur nyaman guna</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>sumpah pake tidak efek 2 pake jerawat udah ker...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>cocok banget anak sekolah murah hasil oke banget</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>insecure banget bopeng udah pede</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>inget ya hilang pudar pakai rutin udah coba</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>worth it banget harga hasil tidak bohong</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>udah pakai pakai 3 minggu bopeng byebye suka b...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>order shopee emang bagus nih krim</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>layan ramah fast response</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>pokok bintang deh produk luv banget</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>nemu skincare cocok tidak bikin kantong kering</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>cowok cuek awat jerawat krim beneran ampuh red...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>tidak nyangka hasil cepat recommended banget</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>produk beautyhacks tidak kecewa</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>tidak kecewa beli kirim dikit tidak</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>kirim cepet packingnya rapi</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>udah pake minggu udah liat hasil order nih</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>tekstur lembut ringan kulit suka</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>cocok kalang kulit</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>ringan banget muka kayak skincare mahal pake e...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>lengket kulit eh pas dipake ringan banget</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>pake nih inget banget juang 2023</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113</td>\n",
       "      <td>make proses moga ikhtiar hasil maksimal</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129</td>\n",
       "      <td>kirim cepet ya bekas 2 sampe</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138</td>\n",
       "      <td>pake cocok kalo jerawat 2 aja udah kempis kalo...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>140</td>\n",
       "      <td>bilang selamat kulit breakout parah</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>udah order shopee udah abis 2 cup kayak udah p...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      no                                            comment predicted_label\n",
       "0      1  pake sunscreen krim doang alhamdulillah tahun ...         positif\n",
       "1      2                  simpen keranjang kuning check out         negatif\n",
       "2      3                 muka kusam segeran rutin pake krim         positif\n",
       "4      5                               misteri dr fay bagus         negatif\n",
       "5      6  banyakin produk kayak gin anak kuliah minim bu...         positif\n",
       "6      7  udah check out kak kemarin udah abis cocok banget         positif\n",
       "7      8  orang tidak percaya kalo beli online kali beli...         negatif\n",
       "8      9                 pake alhamdulillah hasil udah liat         positif\n",
       "9     10                           hasil nyata bagus banget         positif\n",
       "11    12                               cocok banget makasih         positif\n",
       "12    13       kak udah abis 3 pot nih udah langgan bonusin         positif\n",
       "13    14        krim ringan tidak lengket bikin kulit halus         positif\n",
       "15    16                                    caricari ketemu         negatif\n",
       "16    17           langgan mah ngerasain banget insecurenya         positif\n",
       "17    18                    dibeliin istri pake emang sabar         negatif\n",
       "18    19                                 suka banget produk         positif\n",
       "19    20   tementemenku nanyain pake skincare muka ku cerah         negatif\n",
       "20    21                             bau enak tidak nyengat         positif\n",
       "21    22  2 bulan udah pudar pudar total udah bantu itun...         positif\n",
       "22    23                        pakenya gampang cepet resap         positif\n",
       "23    24  hasil maksimal pake rutin tidur hasil bagus kayak         positif\n",
       "24    25  saranin kalo hasil bagus pake facial wash pake...         positif\n",
       "27    28               tidak rasa bulan pake udah hasil aja          netral\n",
       "29    30                                tekstur nyaman guna          netral\n",
       "32    33  sumpah pake tidak efek 2 pake jerawat udah ker...         positif\n",
       "36    37   cocok banget anak sekolah murah hasil oke banget         positif\n",
       "38    39                   insecure banget bopeng udah pede         positif\n",
       "39    40        inget ya hilang pudar pakai rutin udah coba          netral\n",
       "41    42           worth it banget harga hasil tidak bohong         positif\n",
       "44    45  udah pakai pakai 3 minggu bopeng byebye suka b...         positif\n",
       "46    47                  order shopee emang bagus nih krim         positif\n",
       "49    50                          layan ramah fast response         positif\n",
       "52    53                pokok bintang deh produk luv banget         positif\n",
       "54    55     nemu skincare cocok tidak bikin kantong kering         positif\n",
       "57    58  cowok cuek awat jerawat krim beneran ampuh red...         positif\n",
       "62    63       tidak nyangka hasil cepat recommended banget         positif\n",
       "63    64                    produk beautyhacks tidak kecewa         positif\n",
       "67    68                tidak kecewa beli kirim dikit tidak         positif\n",
       "69    70                        kirim cepet packingnya rapi         positif\n",
       "71    72         udah pake minggu udah liat hasil order nih         positif\n",
       "72    73                   tekstur lembut ringan kulit suka         positif\n",
       "73    74                                 cocok kalang kulit         positif\n",
       "74    75  ringan banget muka kayak skincare mahal pake e...         positif\n",
       "87    88          lengket kulit eh pas dipake ringan banget         negatif\n",
       "89    90                   pake nih inget banget juang 2023         positif\n",
       "112  113            make proses moga ikhtiar hasil maksimal         positif\n",
       "128  129                       kirim cepet ya bekas 2 sampe         positif\n",
       "137  138  pake cocok kalo jerawat 2 aja udah kempis kalo...         positif\n",
       "139  140                bilang selamat kulit breakout parah         negatif\n",
       "147  148  udah order shopee udah abis 2 cup kayak udah p...         positif"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaneddataset.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produk ini bagus banget!  smiling_face_with_heart-eyes  sparkles \n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "def replace_emojis(text):\n",
    "    return emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "\n",
    "# Contoh penggunaan\n",
    "text = \"Produk ini bagus banget! üòç‚ú®\"\n",
    "converted_text = replace_emojis(text)\n",
    "print(converted_text)  # Output: \"Produk ini bagus banget! heart_eyes sparkles\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from shap) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from shap) (1.6.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\rfahr\\anaconda3\\lib\\site-packages (from shap) (4.66.5)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from shap) (24.2)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from shap) (0.61.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from numba->shap) (0.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from pandas->shap) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from pandas->shap) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rfahr\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Inisialisasi SHAP\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(\u001b[43mmodel\u001b[49m, tokenizer)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexplain_prediction\u001b[39m(text):\n\u001b[0;32m      8\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# Inisialisasi SHAP\n",
    "explainer = shap.Explainer(model, tokenizer)\n",
    "\n",
    "def explain_prediction(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    shap_values = explainer(inputs)\n",
    "    \n",
    "    # Visualisasi\n",
    "    shap.text_plot(shap_values)\n",
    "\n",
    "# Contoh Analisis\n",
    "comment = \"Pelayanan sangat buruk, saya kecewa!\"\n",
    "explain_prediction(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
